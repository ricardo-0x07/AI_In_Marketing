{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Blog-Gen-v2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ricardo-0x07/AI_In_Marketing/blob/master/Blog_Gen_v2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "eXhFqb6qd7G6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd124256-9231-4214-abdb-968c2b59013d"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import IPython\n",
        "import sys\n",
        "from keras.models import load_model, Model\n",
        "from keras.layers import Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector, CuDNNLSTM, concatenate, SpatialDropout1D\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers import Input, Embedding, Dense, Bidirectional\n",
        "from keras.callbacks import LearningRateScheduler, Callback\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from keras import backend as K\n",
        "from google.colab import files\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import h5py\n",
        "import csv\n",
        "import numpy as np\n",
        "from pkg_resources import resource_filename"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "-5fXoOsLeTXC",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "393ae10b-c478-45f4-df46-9cd29ec7bf2b"
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "all_files = [(name, os.path.getmtime(name)) for name in os.listdir()]\n",
        "latest_file = sorted(all_files, key=lambda x: -x[1])[0][0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3f65c488-28d6-4542-8b08-cb7d71e32ba1\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-3f65c488-28d6-4542-8b08-cb7d71e32ba1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving articles.csv to articles.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R-G5esvGqkFk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc25ed45-954d-4f7a-fb8f-eb91e981139a"
      },
      "cell_type": "code",
      "source": [
        "latest_file"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'articles.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "AiUhl0bbqwSD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def texts_from_file(file_path, header=True,\n",
        "                               delim='\\n', is_csv=False):\n",
        "    '''\n",
        "    Retrieves texts from a newline-delimited file and returns as a list.\n",
        "    '''\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf8', errors='ignore') as f:\n",
        "        if header:\n",
        "            f.readline()\n",
        "        if is_csv:\n",
        "            texts = []\n",
        "            reader = csv.reader(f)\n",
        "            for row in reader:\n",
        "#                 print('row', row[5])\n",
        "                texts.append(row[5])\n",
        "        else:\n",
        "            texts = [line.rstrip(delim) for line in f]\n",
        "\n",
        "    return texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "quK3fQ57sp1B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ea944452-0fb7-4469-dd80-c07f3b594719"
      },
      "cell_type": "code",
      "source": [
        "text = texts_from_file(latest_file, is_csv=True)\n",
        "text = ' '.join(text)\n",
        "print('len(text)', len(text))\n",
        "print(text[:5])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(text) 3747830\n",
            "Oh, h\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YgukbUXOsxMH",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "93b487ab-c4c7-4eb0-91a2-c207a9c74e26"
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "all_files = [(name, os.path.getmtime(name)) for name in os.listdir()]\n",
        "latest_glove_file = sorted(all_files, key=lambda x: -x[1])[0][0]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fe01a949-cb1b-4885-abd2-e942abe533a5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-fe01a949-cb1b-4885-abd2-e942abe533a5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving glove.6B.100d.txt to glove.6B.100d.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C2sGe64zdNT5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_glove_vecs(glove_file):\n",
        "    with open(glove_file, 'r') as f:\n",
        "        words = set()\n",
        "        word_to_vec_map = {}\n",
        "        \n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            curr_word = line[0]\n",
        "            words.add(curr_word)\n",
        "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
        "            \n",
        "    return words, word_to_vec_map\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PSoNtpFXg4Eh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a09b3f01-fcc2-4df7-a862-4c1c17cf1c97"
      },
      "cell_type": "code",
      "source": [
        "latest_glove_file"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'glove.6B.100d.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "m61-6g-cgwnG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words, word_to_vec_map = read_glove_vecs(latest_glove_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ctso64behTrW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: cosine_similarity\n",
        "\n",
        "def cosine_similarity(u, v):\n",
        "    \"\"\"\n",
        "    Cosine similarity reflects the degree of similariy between u and v\n",
        "        \n",
        "    Arguments:\n",
        "        u -- a word vector of shape (n,)          \n",
        "        v -- a word vector of shape (n,)\n",
        "\n",
        "    Returns:\n",
        "        cosine_similarity -- the cosine similarity between u and v defined by the formula above.\n",
        "    \"\"\"\n",
        "    \n",
        "    distance = 0.0\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Compute the dot product between u and v (≈1 line)\n",
        "    dot = np.dot(u,v)\n",
        "    # Compute the L2 norm of u (≈1 line)\n",
        "    norm_u = np.sqrt(np.sum(u**2))\n",
        "    \n",
        "    # Compute the L2 norm of v (≈1 line)\n",
        "    norm_v = np.sqrt(np.sum(v**2))\n",
        "    # Compute the cosine similarity defined by formula (1) (≈1 line)\n",
        "    cosine_similarity = dot/(norm_u*norm_v)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return cosine_similarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NManTP5Kg3LN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a666eac9-2f89-418f-f044-908c82e1be92"
      },
      "cell_type": "code",
      "source": [
        "father = word_to_vec_map[\"father\"]\n",
        "mother = word_to_vec_map[\"mother\"]\n",
        "ball = word_to_vec_map[\"ball\"]\n",
        "crocodile = word_to_vec_map[\"crocodile\"]\n",
        "france = word_to_vec_map[\"france\"]\n",
        "italy = word_to_vec_map[\"italy\"]\n",
        "paris = word_to_vec_map[\"paris\"]\n",
        "rome = word_to_vec_map[\"rome\"]\n",
        "\n",
        "print(\"cosine_similarity(father, mother) = \", cosine_similarity(father, mother))\n",
        "print(\"cosine_similarity(ball, crocodile) = \",cosine_similarity(ball, crocodile))\n",
        "print(\"cosine_similarity(france - paris, rome - italy) = \",cosine_similarity(france - paris, rome - italy))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cosine_similarity(father, mother) =  0.8656661174315731\n",
            "cosine_similarity(ball, crocodile) =  0.15206575219836116\n",
            "cosine_similarity(france - paris, rome - italy) =  -0.7056238800453161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-yLehh0phaO6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Create a new LSTM layer per parameters. Unfortunately,\n",
        "each combination of parameters must be hardcoded.\n",
        "The normal LSTMs use sigmoid recurrent activations\n",
        "for parity with CuDNNLSTM:\n",
        "https://github.com/keras-team/keras/issues/8860\n",
        "'''\n",
        "\n",
        "\n",
        "def new_rnn(cfg, layer_num):\n",
        "    has_gpu = len(K.tensorflow_backend._get_available_gpus()) > 0\n",
        "    if has_gpu:\n",
        "        if cfg['rnn_bidirectional']:\n",
        "            return Bidirectional(CuDNNLSTM(cfg['rnn_size'],\n",
        "                                           return_sequences=True),\n",
        "                                 name='rnn_{}'.format(layer_num))\n",
        "\n",
        "        return CuDNNLSTM(cfg['rnn_size'],\n",
        "                         return_sequences=True,\n",
        "                         name='rnn_{}'.format(layer_num))\n",
        "    else:\n",
        "        if cfg['rnn_bidirectional']:\n",
        "            return Bidirectional(LSTM(cfg['rnn_size'],\n",
        "                                      return_sequences=True,\n",
        "                                      recurrent_activation='sigmoid'),\n",
        "                                 name='rnn_{}'.format(layer_num))\n",
        "\n",
        "        return LSTM(cfg['rnn_size'],\n",
        "                    return_sequences=True,\n",
        "                    recurrent_activation='sigmoid',\n",
        "                    name='rnn_{}'.format(layer_num))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o-ubdNXpqGzK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def textgenrnn_model(num_classes, cfg, context_size=None,\n",
        "                     weights_path=None,\n",
        "                     dropout=0.0,\n",
        "                     optimizer=RMSprop(lr=4e-3, rho=0.99),\n",
        "                     embedding_matrix=None):\n",
        "    '''\n",
        "    Builds the model architecture and\n",
        "    loads the specified weights for the model.\n",
        "    '''\n",
        "\n",
        "    input = Input(shape=(cfg['max_length'],), name='input')\n",
        "    if embedding_matrix is not None:\n",
        "      embedded = Embedding(num_classes,\n",
        "                            cfg['dim_embeddings'],\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=cfg['max_length'],\n",
        "                            trainable=False,\n",
        "                            name='embedding')(input)\n",
        "    else:\n",
        "      embedded = Embedding(num_classes, cfg['dim_embeddings'],\n",
        "                         input_length=cfg['max_length'],\n",
        "                         name='embedding')(input)\n",
        "\n",
        "    if dropout > 0.0:\n",
        "        embedded = SpatialDropout1D(dropout, name='dropout')(embedded)\n",
        "\n",
        "    rnn_layer_list = []\n",
        "    for i in range(cfg['rnn_layers']):\n",
        "        prev_layer = embedded if i is 0 else rnn_layer_list[-1]\n",
        "        rnn_layer_list.append(new_rnn(cfg, i+1)(prev_layer))\n",
        "\n",
        "    seq_concat = concatenate([embedded] + rnn_layer_list, name='rnn_concat')\n",
        "    attention = AttentionWeightedAverage(name='attention')(seq_concat)\n",
        "    output = Dense(num_classes, name='output', activation='softmax')(attention)\n",
        "\n",
        "    if context_size is None:\n",
        "        model = Model(inputs=[input], outputs=[output])\n",
        "        if weights_path is not None:\n",
        "            model.load_weights(weights_path, by_name=True)\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    else:\n",
        "        context_input = Input(\n",
        "            shape=(context_size,), name='context_input')\n",
        "        context_reshape = Reshape((context_size,),\n",
        "                                  name='context_reshape')(context_input)\n",
        "        merged = concatenate([attention, context_reshape], name='concat')\n",
        "        main_output = Dense(num_classes, name='context_output',\n",
        "                            activation='softmax')(merged)\n",
        "\n",
        "        model = Model(inputs=[input, context_input],\n",
        "                      outputs=[main_output, output])\n",
        "        if weights_path is not None:\n",
        "            model.load_weights(weights_path, by_name=True)\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
        "                      loss_weights=[0.8, 0.2])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3myB9PBmrY70",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def process_sequence(X, textgenrnn, new_tokenizer):\n",
        "    X = np.array(X)\n",
        "    X = new_tokenizer.texts_to_sequences(X)\n",
        "#     print('process_sequence X', X)\n",
        "    X = sequence.pad_sequences(\n",
        "        X, maxlen=textgenrnn.config['max_length'])\n",
        "\n",
        "    return X\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vlt1N0X7r2kf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_sequences_from_texts(texts, indices_list,\n",
        "                                  textgenrnn, context_labels,\n",
        "                                  batch_size=128):\n",
        "    is_words = textgenrnn.config['word_level']\n",
        "    is_single = textgenrnn.config['single_text']\n",
        "    max_length = textgenrnn.config['max_length']\n",
        "    meta_token = textgenrnn.META_TOKEN\n",
        "\n",
        "    if is_words:\n",
        "        new_tokenizer = Tokenizer(filters='', char_level=True)\n",
        "        new_tokenizer.word_index = textgenrnn.vocab\n",
        "    else:\n",
        "        new_tokenizer = textgenrnn.tokenizer\n",
        "\n",
        "    while True:\n",
        "        np.random.shuffle(indices_list)\n",
        "\n",
        "        X_batch = []\n",
        "        Y_batch = []\n",
        "        context_batch = []\n",
        "        count_batch = 0\n",
        "\n",
        "        for row in range(indices_list.shape[0]):\n",
        "            text_index = indices_list[row, 0]\n",
        "            end_index = indices_list[row, 1]\n",
        "\n",
        "            text = texts[text_index]\n",
        "\n",
        "            if not is_single:\n",
        "                text = [meta_token] + list(text) + [meta_token]\n",
        "\n",
        "            if end_index > max_length:\n",
        "                x = text[end_index - max_length: end_index + 1]\n",
        "            else:\n",
        "                x = text[0: end_index + 1]\n",
        "            y = text[end_index + 1]\n",
        "\n",
        "            if y in textgenrnn.vocab:\n",
        "                x = process_sequence([x], textgenrnn, new_tokenizer)\n",
        "                y = textgenrnn_encode_cat([y], textgenrnn.vocab)\n",
        "\n",
        "                X_batch.append(x)\n",
        "                Y_batch.append(y)\n",
        "\n",
        "                if context_labels is not None:\n",
        "                    context_batch.append(context_labels[text_index])\n",
        "\n",
        "                count_batch += 1\n",
        "\n",
        "                if count_batch % batch_size == 0:\n",
        "                    X_batch = np.squeeze(np.array(X_batch))\n",
        "                    Y_batch = np.squeeze(np.array(Y_batch))\n",
        "                    context_batch = np.squeeze(np.array(context_batch))\n",
        "\n",
        "                    # print(X_batch.shape)\n",
        "\n",
        "                    if context_labels is not None:\n",
        "                        yield ([X_batch, context_batch], [Y_batch, Y_batch])\n",
        "                    else:\n",
        "                        yield (X_batch, Y_batch)\n",
        "                    X_batch = []\n",
        "                    Y_batch = []\n",
        "                    context_batch = []\n",
        "                    count_batch = 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z_LyAQqC4HUf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def textgenrnn_sample(preds, temperature):\n",
        "    '''\n",
        "    Samples predicted probabilities of the next character to allow\n",
        "    for the network to show \"creativity.\"\n",
        "    '''\n",
        "\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "\n",
        "    if temperature is None or temperature == 0.0:\n",
        "        return np.argmax(preds)\n",
        "\n",
        "    preds = np.log(preds + K.epsilon()) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    index = np.argmax(probas)\n",
        "\n",
        "    # prevent function from being able to choose 0 (placeholder)\n",
        "    # choose 2nd best index from preds\n",
        "    if index == 0:\n",
        "        index = np.argsort(preds)[-2]\n",
        "\n",
        "    return index\n",
        "\n",
        "\n",
        "def textgenrnn_generate(model, vocab,\n",
        "                        indices_char, prefix=None, temperature=0.5,\n",
        "                        maxlen=40, meta_token='<s>',\n",
        "                        word_level=False,\n",
        "                        single_text=False,\n",
        "                        max_gen_length=300):\n",
        "    '''\n",
        "    Generates and returns a single text.\n",
        "    '''\n",
        "\n",
        "    if single_text:\n",
        "        text = list(prefix) if prefix else ['']\n",
        "        max_gen_length += maxlen\n",
        "    else:\n",
        "        text = [meta_token] + list(prefix) if prefix else [meta_token]\n",
        "    next_char = ''\n",
        "\n",
        "    if not isinstance(temperature, list):\n",
        "        temperature = [temperature]\n",
        "\n",
        "    if model_input_count(model) > 1:\n",
        "        model = Model(inputs=model.input[0], outputs=model.output[1])\n",
        "\n",
        "    while next_char != meta_token and len(text) < max_gen_length:\n",
        "        encoded_text = textgenrnn_encode_sequence(text[-maxlen:],\n",
        "                                                  vocab, maxlen)\n",
        "        next_temperature = temperature[(len(text) - 1) % len(temperature)]\n",
        "        next_index = textgenrnn_sample(\n",
        "            model.predict(encoded_text, batch_size=1)[0],\n",
        "            next_temperature)\n",
        "        next_char = indices_char[next_index]\n",
        "        text += [next_char]\n",
        "\n",
        "    collapse_char = ' ' if word_level else ''\n",
        "\n",
        "    # if single text, ignore sequences generated w/ padding\n",
        "    # if not single text, strip the <s> meta_tokens\n",
        "    if single_text:\n",
        "        text = text[maxlen:]\n",
        "    else:\n",
        "        text = text[1:-1]\n",
        "\n",
        "    text_joined = collapse_char.join(text)\n",
        "\n",
        "    # If word level, remove spaces around punctuation for cleanliness.\n",
        "    if word_level:\n",
        "        #     left_punct = \"!%),.:;?@]_}\\\\n\\\\t'\"\n",
        "        #     right_punct = \"$([_\\\\n\\\\t'\"\n",
        "        punct = '\\\\n\\\\t'\n",
        "        text_joined = re.sub(\" ([{}]) \".format(punct), r'\\1', text_joined)\n",
        "        #     text_joined = re.sub(\" ([{}])\".format(\n",
        "        #       left_punct), r'\\1', text_joined)\n",
        "        #     text_joined = re.sub(\"([{}]) \".format(\n",
        "        #       right_punct), r'\\1', text_joined)\n",
        "\n",
        "    return text_joined\n",
        "\n",
        "\n",
        "def textgenrnn_encode_sequence(text, vocab, maxlen):\n",
        "    '''\n",
        "    Encodes a text into the corresponding encoding for prediction with\n",
        "    the model.\n",
        "    '''\n",
        "\n",
        "    encoded = np.array([vocab.get(x, 0) for x in text])\n",
        "    return sequence.pad_sequences([encoded], maxlen=maxlen)\n",
        "\n",
        "\n",
        "def textgenrnn_texts_from_file(file_path, header=True,\n",
        "                               delim='\\n', is_csv=False):\n",
        "    '''\n",
        "    Retrieves texts from a newline-delimited file and returns as a list.\n",
        "    '''\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf8', errors='ignore') as f:\n",
        "        if header:\n",
        "            f.readline()\n",
        "        if is_csv:\n",
        "            texts = []\n",
        "            reader = csv.reader(f)\n",
        "            for row in reader:\n",
        "                texts.append(row[0])\n",
        "        else:\n",
        "            texts = [line.rstrip(delim) for line in f]\n",
        "\n",
        "    return texts\n",
        "\n",
        "\n",
        "def textgenrnn_texts_from_file_context(file_path, header=True):\n",
        "    '''\n",
        "    Retrieves texts+context from a two-column CSV.\n",
        "    '''\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf8', errors='ignore') as f:\n",
        "        if header:\n",
        "            f.readline()\n",
        "        texts = []\n",
        "        context_labels = []\n",
        "        reader = csv.reader(f)\n",
        "        for row in reader:\n",
        "            texts.append(row[0])\n",
        "            context_labels.append(row[1])\n",
        "\n",
        "    return (texts, context_labels)\n",
        "\n",
        "\n",
        "def textgenrnn_encode_cat(chars, vocab):\n",
        "    '''\n",
        "    One-hot encodes values at given chars efficiently by preallocating\n",
        "    a zeros matrix.\n",
        "    '''\n",
        "\n",
        "    a = np.float32(np.zeros((len(chars), len(vocab) + 1)))\n",
        "    rows, cols = zip(*[(i, vocab.get(char, 0))\n",
        "                       for i, char in enumerate(chars)])\n",
        "    a[rows, cols] = 1\n",
        "    return a\n",
        "\n",
        "\n",
        "def model_input_count(model):\n",
        "    if isinstance(model.input, list):\n",
        "        return len(model.input)\n",
        "    else:   # is a Tensor\n",
        "        return model.input.shape[0]\n",
        "\n",
        "\n",
        "class generate_after_epoch(Callback):\n",
        "    def __init__(self, textgenrnn, gen_epochs, max_gen_length):\n",
        "        self.textgenrnn = textgenrnn\n",
        "        self.gen_epochs = gen_epochs\n",
        "        self.max_gen_length = max_gen_length\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if self.gen_epochs > 0 and (epoch+1) % self.gen_epochs == 0:\n",
        "            self.textgenrnn.generate_samples(\n",
        "                max_gen_length=self.max_gen_length)\n",
        "\n",
        "\n",
        "class save_model_weights(Callback):\n",
        "    def __init__(self, weights_name):\n",
        "        self.weights_name = weights_name\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if model_input_count(self.model) > 1:\n",
        "            self.model = Model(inputs=self.model.input[0],\n",
        "                               outputs=self.model.output[1])\n",
        "        self.model.save_weights(\"{}_weights.hdf5\".format(self.weights_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dUyY9UdEI2ux",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "c9313f85-d5dd-4707-ada1-99fda61ea111"
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "all_files = [(name, os.path.getmtime(name)) for name in os.listdir()]\n",
        "vocab_file = sorted(all_files, key=lambda x: -x[1])[0][0]\n",
        "vocab_file"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aa4e0e0d-beb3-432d-b23c-a35066527c35\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-aa4e0e0d-beb3-432d-b23c-a35066527c35\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving textgenrnn_vocab.json to textgenrnn_vocab.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'textgenrnn_vocab.json'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "E-kOR1MJJlDz",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "cfbc903c-7d87-4ca4-8a8c-8494c760c4a9"
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "all_files = [(name, os.path.getmtime(name)) for name in os.listdir()]\n",
        "weight_file = sorted(all_files, key=lambda x: -x[1])[0][0]\n",
        "weight_file"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4904b10b-af87-4a44-880a-c3548472f1cf\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4904b10b-af87-4a44-880a-c3548472f1cf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving textgenrnn_weights.hdf5 to textgenrnn_weights.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'textgenrnn_weights.hdf5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "8whDoqAN1zEX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class textgenrnn:\n",
        "    META_TOKEN = '<s>'\n",
        "    config = {\n",
        "        'rnn_layers': 2,\n",
        "        'rnn_size': 128,\n",
        "        'rnn_bidirectional': False,\n",
        "        'max_length': 40,\n",
        "        'max_words': 10000,\n",
        "        'dim_embeddings': 100,\n",
        "        'word_level': False,\n",
        "        'single_text': False\n",
        "    }\n",
        "    default_config = config.copy()\n",
        "\n",
        "    def __init__(self, weights_path=None,\n",
        "                 vocab_path=None,\n",
        "                 config_path=None,\n",
        "                 name=\"textgenrnn\"):\n",
        "\n",
        "        if weights_path is None:\n",
        "            weights_path = resource_filename(__name__,\n",
        "                                             'textgenrnn_weights.hdf5')\n",
        "\n",
        "        if vocab_path is None:\n",
        "            vocab_path = resource_filename(__name__,\n",
        "                                           'textgenrnn_vocab.json')\n",
        "\n",
        "        if config_path is not None:\n",
        "            with open(config_path, 'r',\n",
        "                      encoding='utf8', errors='ignore') as json_file:\n",
        "                self.config = json.load(json_file)\n",
        "\n",
        "        self.config.update({'name': name})\n",
        "        self.default_config.update({'name': name})\n",
        "\n",
        "        with open(vocab_path, 'r',\n",
        "                  encoding='utf8', errors='ignore') as json_file:\n",
        "            self.vocab = json.load(json_file)\n",
        "\n",
        "        self.tokenizer = Tokenizer(filters='', char_level=True)\n",
        "        self.tokenizer.word_index = self.vocab\n",
        "        self.num_classes = len(self.vocab) + 1\n",
        "        self.model = textgenrnn_model(self.num_classes,\n",
        "                                      cfg=self.config,\n",
        "                                      weights_path=weights_path)\n",
        "        self.indices_char = dict((self.vocab[c], c) for c in self.vocab)\n",
        "\n",
        "    def generate(self, n=1, return_as_list=False, prefix=None,\n",
        "                 temperature=0.5, max_gen_length=300):\n",
        "        gen_texts = []\n",
        "        for _ in range(n):\n",
        "            gen_text = textgenrnn_generate(self.model,\n",
        "                                           self.vocab,\n",
        "                                           self.indices_char,\n",
        "                                           prefix,\n",
        "                                           temperature,\n",
        "                                           self.config['max_length'],\n",
        "                                           self.META_TOKEN,\n",
        "                                           self.config['word_level'],\n",
        "                                           self.config.get(\n",
        "                                               'single_text', False),\n",
        "                                           max_gen_length)\n",
        "            if not return_as_list:\n",
        "                print(\"{}\\n\".format(gen_text))\n",
        "            gen_texts.append(gen_text)\n",
        "        if return_as_list:\n",
        "            return gen_texts\n",
        "\n",
        "    def generate_samples(self, n=3, temperatures=[0.2, 0.5, 1.0], **kwargs):\n",
        "        for temperature in temperatures:\n",
        "            print('#'*20 + '\\nTemperature: {}\\n'.format(temperature) +\n",
        "                  '#'*20)\n",
        "            self.generate(n, temperature=temperature, **kwargs)\n",
        "\n",
        "    def train_on_texts(self, texts, context_labels=None,\n",
        "                       batch_size=128,\n",
        "                       num_epochs=50,\n",
        "                       verbose=1,\n",
        "                       new_model=False,\n",
        "                       gen_epochs=1,\n",
        "                       train_size=1.0,\n",
        "                       max_gen_length=300,\n",
        "                       validation=True,\n",
        "                       dropout=0.0,\n",
        "                       via_new_model=False,\n",
        "                       **kwargs):\n",
        "\n",
        "        if new_model and not via_new_model:\n",
        "            self.train_new_model(texts,\n",
        "                                 context_labels=context_labels,\n",
        "                                 num_epochs=num_epochs,\n",
        "                                 gen_epochs=gen_epochs,\n",
        "                                 batch_size=batch_size,\n",
        "                                 dropout=dropout,\n",
        "                                 validation=validation,\n",
        "                                 **kwargs)\n",
        "            return\n",
        "\n",
        "        if context_labels:\n",
        "            context_labels = LabelBinarizer().fit_transform(context_labels)\n",
        "\n",
        "        if 'prop_keep' in kwargs:\n",
        "            train_size = prop_keep\n",
        "\n",
        "        if self.config['word_level']:\n",
        "            texts = [text_to_word_sequence(text, filters='') for text in texts]\n",
        "\n",
        "        # calculate all combinations of text indices + token indices\n",
        "        indices_list = [np.meshgrid(np.array(i), np.arange(\n",
        "            len(text) + 1)) for i, text in enumerate(texts)]\n",
        "        indices_list = np.block(indices_list)\n",
        "\n",
        "        # If a single text, there will be 2 extra indices, so remove them\n",
        "        # Also remove first sequences which use padding\n",
        "        if self.config['single_text']:\n",
        "            indices_list = indices_list[self.config['max_length']:-2, :]\n",
        "\n",
        "        indices_mask = np.random.rand(indices_list.shape[0]) < train_size\n",
        "\n",
        "        gen_val = None\n",
        "        val_steps = None\n",
        "        if train_size < 1.0 and validation:\n",
        "            indices_list_val = indices_list[~indices_mask, :]\n",
        "            gen_val = generate_sequences_from_texts(\n",
        "                texts, indices_list_val, self, context_labels, batch_size)\n",
        "            val_steps = max(\n",
        "                int(np.floor(indices_list_val.shape[0] / batch_size)), 1)\n",
        "\n",
        "        indices_list = indices_list[indices_mask, :]\n",
        "\n",
        "        num_tokens = indices_list.shape[0]\n",
        "        assert num_tokens >= batch_size, \"Fewer tokens than batch_size.\"\n",
        "\n",
        "        level = 'word' if self.config['word_level'] else 'character'\n",
        "        print(\"Training on {:,} {} sequences.\".format(num_tokens, level))\n",
        "\n",
        "        steps_per_epoch = max(int(np.floor(num_tokens / batch_size)), 1)\n",
        "        print('vocab texts', texts)\n",
        "\n",
        "        gen = generate_sequences_from_texts(\n",
        "            texts, indices_list, self, context_labels, batch_size)\n",
        "\n",
        "        base_lr = 4e-3\n",
        "\n",
        "        # scheduler function must be defined inline.\n",
        "        def lr_linear_decay(epoch):\n",
        "            return (base_lr * (1 - (epoch / num_epochs)))\n",
        "\n",
        "        if context_labels is not None:\n",
        "            if new_model:\n",
        "                weights_path = None\n",
        "            else:\n",
        "                weights_path = \"{}_weights.hdf5\".format(self.config['name'])\n",
        "                self.save(weights_path)\n",
        "\n",
        "            self.model = textgenrnn_model(self.num_classes,\n",
        "                                          dropout=dropout,\n",
        "                                          cfg=self.config,\n",
        "                                          context_size=context_labels.shape[1],\n",
        "                                          weights_path=weights_path)\n",
        "\n",
        "        self.model.fit_generator(gen, steps_per_epoch=steps_per_epoch,\n",
        "                                 epochs=num_epochs,\n",
        "                                 callbacks=[\n",
        "                                     LearningRateScheduler(\n",
        "                                         lr_linear_decay),\n",
        "                                     generate_after_epoch(\n",
        "                                         self, gen_epochs,\n",
        "                                         max_gen_length),\n",
        "                                     save_model_weights(\n",
        "                                         self.config['name'])],\n",
        "                                 verbose=verbose,\n",
        "                                 max_queue_size=2,\n",
        "                                 validation_data=gen_val,\n",
        "                                 validation_steps=val_steps\n",
        "                                 )\n",
        "\n",
        "        # Keep the text-only version of the model if using context labels\n",
        "        if context_labels is not None:\n",
        "            self.model = Model(inputs=self.model.input[0],\n",
        "                               outputs=self.model.output[1])\n",
        "\n",
        "    def train_new_model(self, texts, context_labels=None, num_epochs=50,\n",
        "                        gen_epochs=1, batch_size=128, dropout=0.0,\n",
        "                        validation=True, **kwargs):\n",
        "        self.config = self.default_config.copy()\n",
        "        self.config.update(**kwargs)\n",
        "\n",
        "        print(\"Training new model w/ {}-layer, {}-cell {}LSTMs\".format(\n",
        "            self.config['rnn_layers'], self.config['rnn_size'],\n",
        "            'Bidirectional ' if self.config['rnn_bidirectional'] else ''\n",
        "        ))\n",
        "\n",
        "        # If training word level, must add spaces around each punctuation.\n",
        "        # https://stackoverflow.com/a/3645946/9314418\n",
        "\n",
        "        if self.config['word_level']:\n",
        "            punct = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\\\n\\\\t\\'‘’“”’–—'\n",
        "            for i in range(len(texts)):\n",
        "                texts[i] = re.sub('([{}])'.format(punct), r' \\1 ', texts[i])\n",
        "                texts[i] = re.sub(' {2,}', ' ', texts[i])\n",
        "\n",
        "        # Create text vocabulary for new texts\n",
        "        self.tokenizer = Tokenizer(filters='',\n",
        "                                   char_level=(not self.config['word_level']))\n",
        "        self.tokenizer.fit_on_texts(texts)\n",
        "\n",
        "        # Limit vocab to max_words\n",
        "        max_words = self.config['max_words']\n",
        "        self.tokenizer.word_index = {k: v for (\n",
        "            k, v) in self.tokenizer.word_index.items() if v <= max_words}\n",
        "\n",
        "        if not self.config.get('single_text', False):\n",
        "            self.tokenizer.word_index[self.META_TOKEN] = len(\n",
        "                self.tokenizer.word_index) + 1\n",
        "        self.vocab = self.tokenizer.word_index\n",
        "        self.num_classes = len(self.vocab) + 1\n",
        "        self.indices_char = dict((self.vocab[c], c) for c in self.vocab)\n",
        "        \n",
        "        # prepare embedding matrix\n",
        "#         num_words = min(max_words, len(self.vocab) + 1)\n",
        "        num_words = len(self.vocab) + 1\n",
        "        embedding_matrix = np.zeros((num_words, self.config['dim_embeddings']))\n",
        "        print('embedding_matrix.shape', embedding_matrix.shape)\n",
        "        for word, i in self.vocab.items():\n",
        "            if i >= max_words:\n",
        "                continue\n",
        "            embedding_vector = word_to_vec_map.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                # words not found in embedding index will be all-zeros.\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "\n",
        "\n",
        "        # Create a new, blank model w/ given params\n",
        "        self.model = textgenrnn_model(self.num_classes,\n",
        "                                      dropout=dropout,\n",
        "                                      cfg=self.config,\n",
        "                                      embedding_matrix=embedding_matrix)\n",
        "\n",
        "        # Save the files needed to recreate the model\n",
        "        with open('{}_vocab.json'.format(self.config['name']),\n",
        "                  'w', encoding='utf8') as outfile:\n",
        "            json.dump(self.tokenizer.word_index, outfile, ensure_ascii=False)\n",
        "\n",
        "        with open('{}_config.json'.format(self.config['name']),\n",
        "                  'w', encoding='utf8') as outfile:\n",
        "            json.dump(self.config, outfile, ensure_ascii=False)\n",
        "\n",
        "        self.train_on_texts(texts, new_model=True,\n",
        "                            via_new_model=True,\n",
        "                            context_labels=context_labels,\n",
        "                            num_epochs=num_epochs,\n",
        "                            gen_epochs=gen_epochs,\n",
        "                            batch_size=batch_size,\n",
        "                            dropout=dropout,\n",
        "                            validation=validation,\n",
        "                            **kwargs)\n",
        "\n",
        "    def save(self, weights_path=\"textgenrnn_weights_saved.hdf5\"):\n",
        "        self.model.save_weights(weights_path)\n",
        "\n",
        "    def load(self, weights_path):\n",
        "        self.model = textgenrnn_model(self.num_classes,\n",
        "                                      cfg=self.config,\n",
        "                                      weights_path=weights_path)\n",
        "\n",
        "    def reset(self):\n",
        "        self.config = self.default_config.copy()\n",
        "        self.__init__(name=self.config['name'])\n",
        "\n",
        "    def train_from_file(self, file_path, header=True, delim=\"\\n\",\n",
        "                        new_model=False, context=None,\n",
        "                        is_csv=False, **kwargs):\n",
        "\n",
        "        context_labels = None\n",
        "        if context:\n",
        "            texts, context_labels = textgenrnn_texts_from_file_context(\n",
        "                file_path)\n",
        "        else:\n",
        "            texts = texts_from_file(file_path, header,\n",
        "                                               delim, is_csv)\n",
        "#             texts = textgenrnn_texts_from_file(file_path, header,\n",
        "#                                                delim, is_csv)\n",
        "\n",
        "        print(\"{:,} texts collected.\".format(len(texts)))\n",
        "        if new_model:\n",
        "            self.train_new_model(\n",
        "                texts, context_labels=context_labels, **kwargs)\n",
        "        else:\n",
        "            self.train_on_texts(texts, context_labels=context_labels, **kwargs)\n",
        "\n",
        "    def train_from_largetext_file(self, file_path, new_model=True, **kwargs):\n",
        "        with open(file_path, 'r', encoding='utf8', errors='ignore') as f:\n",
        "            texts = [f.read()]\n",
        "\n",
        "        if new_model:\n",
        "            self.train_new_model(\n",
        "                texts, single_text=True, **kwargs)\n",
        "        else:\n",
        "            self.train_on_texts(texts, single_text=True, **kwargs)\n",
        "\n",
        "    def generate_to_file(self, destination_path, **kwargs):\n",
        "        texts = self.generate(return_as_list=True, **kwargs)\n",
        "        with open(destination_path, 'w') as f:\n",
        "            for text in texts:\n",
        "                f.write(\"{}\\n\".format(text))\n",
        "\n",
        "    def encode_text_vectors(self, texts, pca_dims=50, tsne_dims=None,\n",
        "                            tsne_seed=None, return_pca=False,\n",
        "                            return_tsne=False):\n",
        "\n",
        "        # if a single text, force it into a list:\n",
        "        if isinstance(texts, str):\n",
        "            texts = [texts]\n",
        "\n",
        "        vector_output = Model(inputs=self.model.input,\n",
        "                              outputs=self.model.get_layer('attention').output)\n",
        "        encoded_vectors = []\n",
        "        maxlen = self.config['max_length']\n",
        "        for text in texts:\n",
        "            if self.config['word_level']:\n",
        "                text = text_to_word_sequence(text, filters='')\n",
        "            text_aug = [self.META_TOKEN] + list(text[0:maxlen])\n",
        "            encoded_text = textgenrnn_encode_sequence(text_aug, self.vocab,\n",
        "                                                      maxlen)\n",
        "            encoded_vector = vector_output.predict(encoded_text)\n",
        "            encoded_vectors.append(encoded_vector)\n",
        "\n",
        "        encoded_vectors = np.squeeze(np.array(encoded_vectors), axis=1)\n",
        "        if pca_dims is not None:\n",
        "            assert len(texts) > 1, \"Must use more than 1 text for PCA\"\n",
        "            pca = PCA(pca_dims)\n",
        "            encoded_vectors = pca.fit_transform(encoded_vectors)\n",
        "\n",
        "        if tsne_dims is not None:\n",
        "            tsne = TSNE(tsne_dims, random_state=tsne_seed)\n",
        "            encoded_vectors = tsne.fit_transform(encoded_vectors)\n",
        "\n",
        "        return_objects = encoded_vectors\n",
        "        if return_pca or return_tsne:\n",
        "            return_objects = [return_objects]\n",
        "        if return_pca:\n",
        "            return_objects.append(pca)\n",
        "        if return_tsne:\n",
        "            return_objects.append(tsne)\n",
        "\n",
        "        return return_objects\n",
        "\n",
        "    def similarity(self, text, texts, use_pca=True):\n",
        "        text_encoded = self.encode_text_vectors(text, pca_dims=None)\n",
        "        if use_pca:\n",
        "            texts_encoded, pca = self.encode_text_vectors(texts,\n",
        "                                                          return_pca=True)\n",
        "            text_encoded = pca.transform(text_encoded)\n",
        "        else:\n",
        "            texts_encoded = self.encode_text_vectors(texts, pca_dims=None)\n",
        "\n",
        "        cos_similairity = cosine_similarity(text_encoded, texts_encoded)[0]\n",
        "        text_sim_pairs = list(zip(texts, cos_similairity))\n",
        "        text_sim_pairs = sorted(text_sim_pairs, key=lambda x: -x[1])\n",
        "        return text_sim_pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ugjoqug1CnFh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.engine import InputSpec, Layer\n",
        "from keras import backend as K\n",
        "from keras import initializers\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class AttentionWeightedAverage(Layer):\n",
        "    \"\"\"\n",
        "    Computes a weighted average of the different channels across timesteps.\n",
        "    Uses 1 parameter pr. channel to compute the attention value for\n",
        "    a single timestep.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, return_attention=False, **kwargs):\n",
        "        self.init = initializers.get('uniform')\n",
        "        self.supports_masking = True\n",
        "        self.return_attention = return_attention\n",
        "        super(AttentionWeightedAverage, self).__init__(** kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_spec = [InputSpec(ndim=3)]\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 initializer=self.init)\n",
        "        self.trainable_weights = [self.W]\n",
        "        super(AttentionWeightedAverage, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        # computes a probability distribution over the timesteps\n",
        "        # uses 'max trick' for numerical stability\n",
        "        # reshape is done to avoid issue with Tensorflow\n",
        "        # and 1-dimensional weights\n",
        "        logits = K.dot(x, self.W)\n",
        "        x_shape = K.shape(x)\n",
        "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
        "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
        "\n",
        "        # masked timesteps have zero weight\n",
        "        if mask is not None:\n",
        "            mask = K.cast(mask, K.floatx())\n",
        "            ai = ai * mask\n",
        "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
        "        weighted_input = x * K.expand_dims(att_weights)\n",
        "        result = K.sum(weighted_input, axis=1)\n",
        "        if self.return_attention:\n",
        "            return [result, att_weights]\n",
        "        return result\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        return self.compute_output_shape(input_shape)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        output_len = input_shape[2]\n",
        "        if self.return_attention:\n",
        "            return [(input_shape[0], output_len), (input_shape[0],\n",
        "                                                   input_shape[1])]\n",
        "        return (input_shape[0], output_len)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        if isinstance(input_mask, list):\n",
        "            return [None] * len(input_mask)\n",
        "        else:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_sX6L3L0C9gN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_cfg = {\n",
        "    'rnn_size': 128,\n",
        "    'rnn_layers': 4,\n",
        "    'rnn_bidirectional': True,\n",
        "    'max_length': 40,\n",
        "    'max_words': 10000,\n",
        "    'dim_embeddings': 100,\n",
        "    'word_level': True,\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': False,\n",
        "    'num_epochs': 10,\n",
        "    'gen_epochs': 2,\n",
        "    'batch_size': 1028,\n",
        "    'train_size': 0.8,\n",
        "    'dropout': 0.0,\n",
        "    'max_gen_length': 300,\n",
        "    'validation': False,\n",
        "    'is_csv': True\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uez-xMrSDlRv",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "21995136-5300-45ad-aad4-9022dcfe96e9"
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "all_files = [(name, os.path.getmtime(name)) for name in os.listdir()]\n",
        "latest_file = sorted(all_files, key=lambda x: -x[1])[0][0]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3cd46c04-4617-49e3-b5ad-73a697904136\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-3cd46c04-4617-49e3-b5ad-73a697904136\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving articles.csv to articles (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uRMz5Xu1DreX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36077
        },
        "outputId": "15edb26f-f38f-4bb2-ff0f-c076c6b5940c"
      },
      "cell_type": "code",
      "source": [
        "model_name = 'colaboratory'\n",
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=latest_file,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=train_cfg['batch_size'],\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    max_gen_length=train_cfg['max_gen_length'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=model_cfg['dim_embeddings'],\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training new model w/ 4-layer, 128-cell Bidirectional LSTMs\n",
            "embedding_matrix.shape (10001, 100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "620/620 [==============================] - 277s 447ms/step - loss: 5.8265\n",
            "Epoch 2/10\n",
            "316/620 [==============>...............] - ETA: 2:12 - loss: 4.2714"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "620/620 [==============================] - 270s 435ms/step - loss: 4.1130\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "output of the output .\n",
            "the output is the output of the neuron :\n",
            "the output of the output is the output of the neuron .\n",
            "the output of the neuron is to reach the output of the output nerve .\n",
            "the output is the output of the neuron to reach the output of the neuron .\n",
            "the neuron is unfortunately initialized by synapse .\n",
            "synapse is called a synapse , which is synapse between synapse . synapse , synapse , synapse . synapse .\n",
            "synapse , synapse receptors are important to be able to excite .\n",
            "the synapse is responsible to be able to excite .\n",
            "implication , it is a synapse of synapse , which is responsible to the synapse , which is able to be responsible to the synapse .\n",
            "synapse , synapse , synapse , synapse , synapse , synapse , synapse . synapse , synapse . synapse .\n",
            "synapse , and receptors .\n",
            "synapse . synapse and receptors are synapse .\n",
            "synapse , synapse receptors are responsible to be synapse .\n",
            "synapse , synapse receptors are on synapse .\n",
            "synapse , synapse , synapse , synapse , synapse , receptors .\n",
            "synapse , synapse . synapse between synapse , synapse receptors are synapse .\n",
            "synapse . synapse , synapse receptors are receptors to be on the cell .\n",
            "synapse , synapse . synapse , synapse receptors .\n",
            "synapse , synapse , synapse , synapse receptors .\n",
            "synapse . synapse , synapse receptors are on the synapse .\n",
            "synapse , synapse , synapse , synapse . synapse , synapse receptors .\n",
            "synapse , synapse receptors are important to be synapse .\n",
            "synapse .\n",
            "\n",
            ".\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            ".\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "มะม่วง\n",
            ".\n",
            "\n",
            " \"\n",
            ", , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , and b . , , & , p . , , , , s . , , & , p . , , & , p . , & p . ( 1 ) , ( 1 ) ( 1 ) , 1 – 330 .\n",
            "( wirth ) . the atoms of the network , we can likely be able to be a good idea to the network .\n",
            "here is a lot more than the network and fast r - cnn features a single network .\n",
            "here is a fairly small number of features :\n",
            "the main network is a single object in the image . it is the main cnn features map in the image .\n",
            "the bounding box is a fairly standard representation of the cnn image .\n",
            "the cnn features map is a fairly small image ( image ) feature map in the image above as fast r - cnn to generate a single cnn features ( cnn ) , which is a cnn to be unapproachable ( a cnn ) to be unapproachable ( a male ) of the image r - cnn image ( a cnn ) , a single object of a single image ( r ) plus ) to inaccuracies ( the branch ) .\n",
            "r - cnn ( where a single ) works in image segmentation ( a ) in cnn (\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "มะม่วง\n",
            "มะม่วง\n",
            "\n",
            " .\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " .\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " .\n",
            "\n",
            " \"\n",
            ", , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , and . . . . . . . . . . . . . . . . . .\n",
            "the future of the future of humanity is not the world , and the world is the world , and the ghosts are being .\n",
            "the world , the ghosts are being being a long , but it ’ s not hard to be able to be able to be able to be able to be able to be able to be able to be able to be able to approximate the value of the function .\n",
            "the model is trained by the model that is the model is the model .\n",
            "the model is trained with a randomly chosen 70 % of the training set .\n",
            "the model is trained with the model _ size is the model .\n",
            "the gtx 1080 ti outperforms the aws k80 ( k80 ) . the mnist algorithm is about the same thing .\n",
            "the gpu is the model _ which is the performance in the image .\n",
            "the 1080 ti is 5 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 .\n",
            "if you can see that the same thing is the same thing is .\n",
            "the\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "cheer to a standing ovation , clap to show how much you enjoyed this story .\n",
            "founder of www . moju . io\n",
            "\"\n",
            ", 20 , https : / / hackernoon . com / the - 1700 - great - deep - learning - box - assembly - of - the - art - of - deep - learning - ? source = tag _ archive - - - - - - - - - - - - - - - - - - - - - - - - , google duplex ml 🤖👶 in the past year , we need a chatbot for a google sheet on the raspberry pi gpu ( k80 ) , we were removed the code in the input :\n",
            "if you want to have a 30 % accuracy on the google sheet .\n",
            "here is the google colab here .\n",
            "the team of the notebook is the notebook of the unreasonable effectiveness of the model at the training set .\n",
            "the model is trained on the machine learning , which is an tensorflow notebook that is the most crucial component of the model .\n",
            "here is a fairly small - sample size of the dataset .\n",
            "here is a lot of hardware to be relatively valuable in a dataset .\n",
            "it is an example of the training set of training data .\n",
            "the model training is set of loading the training data .\n",
            "here ’ s what we want to make the target of the model . check the following equation , it is the model :\n",
            "here is a fairly intensive model that can be used to be auto - predict what we want to predict the outcome\n",
            "\n",
            "- - - - - - - - - - - - - - - - - - - - , - - , understanding cnns and deep learning with tensorflow , \" for this article is the next big deal in the past year .\n",
            "the advent of the world , the of the world of the world , which is the best way to get a good idea of this project .\n",
            "in fact , it ’ s not hard to think that you understand and what is a bit like that ’ s not going to be able to approximate the same .\n",
            "you can also be able to be able to approximate the loss function .\n",
            "in the figure above , the letter is that we have a lot of different words :\n",
            "the first thing is that we can be that the next letter is the letter is a sentence of an error .\n",
            "the model consists of the neural network is trained to generate text text .\n",
            "the network is a condensed version of the network .\n",
            "we did not be a lot more than the network parameters .\n",
            "here is the network ’ s weights , which is the network of the network .\n",
            "here ’ s a single neuron layer to the next layer , which is the output of the output .\n",
            "this is the weights for the output .\n",
            "the ‘ convolution layer is the output of the layer layer 1 . 0 .\n",
            "1 .\n",
            "the output of the input variable _ w _ ( 1 ) = 0 . 0 . 0 , 1 , 0 . 0 . 0 .\n",
            "is the\n",
            "\n",
            "i , and the best consumer system is the code as a matter of what you can be better .\n",
            "the idea of “ google ’ s smart voices in google ’ s “ ” and “ ” and “ boy ” .\n",
            "“ a bit like ” , “ the search engine ” is a language word . ”\n",
            "the “ hello ” , and “ hello ” .\n",
            "“ oh ’ s search to “ ” is a bit in the world . ”\n",
            "“ ” is a bit like this is a direct : ”\n",
            "“ ” is the “ ” factors of the output of the lstms .\n",
            "as the same thing , we ’ ll tell that the rest of the input is 4000 dimensional , it is a little of “ ” .\n",
            "finding the right parameters ( e . g . _ _ _ , z ) = , the f ( a ) is the input variable ( y ) .\n",
            "a threshold is the number of x _ j _ j _ j .\n",
            "( ) = ( 010 ) .\n",
            "_ u ( s ) is the sigmoid function .\n",
            "we can be easier to train .\n",
            "( it ’ s a bit gross error , which is the gradient signal to the sigmoid curve ( ) .\n",
            "the derivative is defined on the derivative of the error w . r . t .\n",
            "the error w is the output of the derivative w w . r . r . t . r . t . the derivative of the derivative w w w ( r ) , which is a much effective matrix multiplication\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "to create human outcomes . seen also been obvious to complete a wide variety less than precisely at the demand of “ behavior ? ”\n",
            "ai let us the structure of 20 % accuracy , advantageous information received as the appearance of a person may not the influence of u maximizers . , which a threat of a conversational conversation bot system is . participants in images of the romance movie , which is the bot , and paper images are selected by those actual human english command from some infancy and applications .\n",
            "it ’ s an bot that mix generally to perform various images of information scenarios which make a lot solutions . yes was a huge fact factor after mine ? we started for google , the social media , which is the bot to always be . but who cares to this - to other sentences . and even we often need to get a little . let ’ s start their messaging army of these issues .\n",
            "the lot — and it is remaining of criteria in data ( e . g . , i , , . ) goes to the simulation , including an strongly - time restaurant for decades from getting the time . for reference nearby the documentation as as candidates , i need all of the exact own jobs , working of choosing their pre - gpu is what it would completed a gpu feature for some 32 hours of on our seen because using the first surroundings of the time . if if albright uncovered whether these changes on their cpu , and we just want to become fewer the time training set . we had heavily our objective for a face during a series at\n",
            "\n",
            ". please contact the bot to correct their super mario brothers levels from scratch for the strongest point . if you recall an ml file from a neural network .\n",
            "this is seemingly hundreds of possible moves @ datacamp .\n",
            "remark into a ‘ word language that is used ” today are examples to zero fee ” ?\n",
            "let ’ s imagine you be feeding . feed them ?\n",
            "let ’ s what idea that you ’ re verify ?\n",
            "the ‘ ’ ’ group isn ’ t really cool for m hair salon ? if these label actually play what ’ s hard !\n",
            "“ i seed ? because “ voice , ” dr and carla me that this actually mean 100 dimensional recipes .\n",
            "here is not good ever , when it was grouping works , or . it goes through and , that is sure formal to it , but as only always time thinking , the pattern between individual neurons work\n",
            "neural network will spare some of sophisticated “ neurons ” society .\n",
            "the neurons of an synapses and imaging is responsible of practical abstractions for us !\n",
            "robinson points to some of this , weight in 68 - % neural network accuracy is low because further a low level features on a pretty good amount , albeit different for random shadows limit random learning rates between an single output of accuracy . lstm during training , let us a key multi - divided connected ownership everywhere in other entry sites . we ’ ll change in a black solution to predict .\n",
            "introduction neural nets is the network to predict the simulation to be used on a cnn instead along a football with .\n",
            "\n",
            "forever we actually need for a c test sentence again :\n",
            "about speech feel like this project is not actually seeing a lot of noticed that has changed to have and before you in the cases .\n",
            "given the time of the paper suggests it ’ s worth noting that blockchain = user . it suggest that , is that it stands all candidates or not at different yet . , if some sources generally which aren ’ t stop to work better more . ( if you don ’ t feeding ) at . one is one . to do so . so it just even we ? , and , he is no enough in what hasn ’ t so also .\n",
            "here is also significant — aspect of this approach there could be fair for a matter of the way but it is given some positive - as give apart , with a professional experience , and then . this process finds to be much to emerge when a menu would be a lot of moving positions to go .\n",
            "as would you speak type of people , not likely away . it makes sense in this topic , a starship system , which said is of . the part of the user is location goods and is in computer full feedback loops between all songs of the target prediction the others , just so simple .\n",
            "in some high volume , you are the was support and candidates to held to a best dominated . on the storing not quickly abandoned , it isn ’ t so one — i lightly invisible . of course , listings they on nancy was just to write effort to support to the button .\n",
            "\n",
            "Epoch 3/10\n",
            "  2/620 [..............................] - ETA: 5:06 - loss: 3.4805"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "620/620 [==============================] - 269s 434ms/step - loss: 3.2308\n",
            "Epoch 4/10\n",
            "385/620 [=================>............] - ETA: 1:43 - loss: 2.6308"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "620/620 [==============================] - 273s 440ms/step - loss: 2.5888\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "neural network ( rnn ) , recurrent neural networks ( rnn ) . lstm ( ) , lstm , & . , , , & , , , , , , & , m . , , t . , & , & gentner , 1989 , 2009 .\n",
            "( emilio , and & mit , 2009 ) . the structure of the structure of the course — the course was on his action .\n",
            "the structure of the structure of the neural network is endless news . we can see that the term is to use the neural network to generalize to unseen from the games .\n",
            "we then use a neural network that can then pass the neural network to recognize pictures from even numbers to odd numbers in the picture .\n",
            "tldr : if you ’ re probably using a neural network in the neural network with an artificial neural network . it has a great more .\n",
            "in the early version of the paper , it ’ s just a bit more — the most important as the neural network was originally published .\n",
            "the idea of the network is that it is not that it needs to understand the ai revolution . in fact , it ’ s impossible to say that the network uses itself . it ’ s not a tool to get a better understanding of how to build a system that needs to be able to be able to predict .\n",
            "in the next version of the paper , we ’ ll be able to understand the world where we ’ re going to use it .\n",
            "we ’ ll use a method that performs the gradient descent to the path . \n",
            "\n",
            "\n",
            "0 - a26a10b68df3 - ? source = tag _ archive - - - - - - - - - - 8 - - - - - - - - - - - - - , \" cheat sheets for neural networks , \" google ’ s data science has moved on december december , originally published at www . howwegettonext . com\n",
            "\"\n",
            "david , , 10 , https : / / towardsdatascience . com / the - bejeweled - - ? source = tag _ archive - - - - - - - - - - - - - - - - - - - - - - - - - , a big data scientist – – medium , \" google ’ s the next big thing i ’ ve been given a full - description of using artificial intelligence . it ’ s a really good thing , i ’ ve been inspired by an artificial intelligence tool .\n",
            "in a short version of the salt world , the salt _ invested created an 90 % + + low of the platform for the world , owning the country of the platform , and the human , the competition of the app show that the app show the launch of a few years , it ’ s not a very high - level , the platform to achieve that was not able to achieve the app without having a store .\n",
            "in the near future , it ’ s hard to beat the app store , which is not enough to sell for the app store .\n",
            "the result of the app was the early graphical interface is crucial the ability to drive the car around either sides .\n",
            "the app\n",
            "\n",
            "- revolution - hasnt - happened - 5fc49dd6fa61 ? source = tag _ archive - - - - - - - - - - 8 - - - - - - - - - - - - - - , how to build a neural network : the secret ai – françois machine learning – medium , \" recently announced , the launch of a “ open - source software ” system , the field of the platform , and the tools are staggering over the amount of data . the second is not a very important task to get for the next .\n",
            "the replay was then the most interesting and highly comprehensive pipeline , and in the original paper , i ran into a league .\n",
            "i ’ ve had a few years from before - i wanted to understand how to use my tool and i ’ ve been working on . i ’ ve been working on the internet to get started on making interesting projects like\n",
            ", or if you want to understand material of my own .\n",
            "website | itunes\n",
            "originally published at www . sciencerockstars . com on the goal of human curation .\n",
            "\"\n",
            ", , 12 , https : / / medium . com / @ / the - bejeweled - - ? source = tag _ archive - - - - - - - - - 9 - - - - - - - - - - - - - - , , do algorithms reveal sexual orientation in the ai app , \" google ’ s word2vec ’ s episode app installs that uses the input to our image and treat it instantly .\n",
            "the app has found for a very\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "- ? source = tag _ archive - - - - - - - - - 9 - - - - - - - - - - - - - - , a mind - blowing ai announcement of google search — google ’ s ai , \" recently wrapped up the year in , and i ’ ve been been involved in various algorithms including google home companies like google ’ s ai ’ s app .\n",
            "is just one of the platform to dominate in the world ’ s terms . in the near future , it ’ s not not to let the ’ ve been able to be able to learn .\n",
            "but also , if you want to get for , if you ’ re still trying to grasp the concept .\n",
            "i ’ ve been working with a couple and a dozen apps that found the data from google ’ s word2vec , so i found this was a computer science bootcamp that was its one .\n",
            "the good thing is that there was still a 4 . 5 mb of machine learning that is used for the second . google gave me a good course , but you ’ ll have all of my ability at the other hardware .\n",
            "the code is mostly used and used .\n",
            "the solution is not a simple amount of dataset by pandas targets . it can mean that the mean we want to do . if it is a bit good , so , we can ’ t wait to see the function as a whole story .\n",
            "we ’ ll see this !\n",
            "the training data set is crucial to understand this .\n",
            "here ’ s\n",
            "\n",
            "- - - - 9 - - - - - - - - - - - - - - - , artificial intelligence – shivon fund – medium , \" update : 1 : from a year of , a recent year , i ’ ve been involved to building the world ’ s most aesthetically appealing as being as possible .\n",
            "sp : “ not it ’ s not a big plus , “ - ” is let ’ s not be either to not something like that ’ s where each of the most difficult part of the transaction . if it ’ s not very similar , because it ’ s not very good !\n",
            "and this is not the same thing , so i ’ ve found a lot of work when i ’ ve always been involved with big data and what i ’ ve been given it . i ’ ve been this post - siri ? source = tag _ archive , did it .\n",
            "i ’ ve read this by google ’ s “ deep learning library .\n",
            "this code is a great style for python . thanks to the essentially data , you need to build a neural network that has a simple task .\n",
            "if you are using a condensed version of the neural network ( you can read that data ) . we ’ ll stick that gradient from each of our error function .\n",
            "after we can use a neural network to estimate the value of the output .\n",
            "tldr is a great article about how to train the network to estimate the value of the next time . a house of the most important network was the two . it\n",
            "\n",
            "обучения обучения обучения обучения обучения в в .\n",
            ".\n",
            "в - и в не , не обучения обучения обучения обучения обучения обучения обучения обучения .\n",
            "обучения обучения обучения обучения обучения \"\n",
            "\"\n",
            ", , 12 , https : / / . com / the - machine - of - machine - learning - in - the - past - ? source = tag _ archive - - - - - - - - - 9 - - - - - - - - - - - - - - - - , the , \" google ’ s word2vec – medium , \" recently announced , i published an article , originally published on an article , originally published at www . . com . com on facebook .\n",
            "in an moderator contributor\n",
            "a team in the , digital product in the platform for the next of the . i . , i also recommend the website on my facebook account .\n",
            "originally published at www . sciencerockstars . com on facebook .\n",
            "if you ’ re going to get a new version of the code . you can discuss the code and add the following :\n",
            "the blog post by google now , facebook is one of the most important topics in the content file , and the most important group on the real challenge .\n",
            "a quick group is to recognize the quality of a post by anyone else else else , and what is what i ’ ve been given a little bit of them , and for the following flow .\n",
            "the structure is simple , but i ’ m not sure what i ’ m going to think of the past , i\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "ai ) , though all this means it will be one of the player that used the basic game with the rise web need to receive by in silence and to journalists . since they have been based on my focus on start . they have preferred time to follow artificial intelligence to readily role tasks . when the focus to part - chain is google ! up on the entire amount of your entry next web . .\n",
            "during the cold graphic of background , means between we actually your own local minimum payment metric , then find the old index of at . the html could need to not specify the conclusions with respect to the map out and then pins should be along . then these graphs are produced stays for each . this noisy process seems quite important . i had a way for three possible possible complex mathematically approach . this is just a score , not the task should be crucial for as long as most commonly writing . when i do no at the start days and it gets so complex — just as per seconds .\n",
            "i submitted these documentation as good as the task with finding an algorithm and above results .\n",
            "if you can do this in my experience , don ’ t come up more advanced ml description of code yours rectangle gradients and the code making the most important trend . again , i might notice that there is easy — the idea of being moving on whether a . where i com should feed a data to that model .\n",
            "building its process of installing ai - powered apps that we can build deep learning , image recognition , a company is a\n",
            "\n",
            ", , . . . . said , , nancy . , , , , facebook profile - companies like all of yale , cambridge analytica ’ s sex and trafficking between man bitcoin and facebook , 2009 , google , and facebook :\n",
            "we ’ re totally analytica , that ’ s a reflection : this story , we ’ ve started looking for system .\n",
            "then , i think i ’ ve laid 256 hearing in the enterprise world instead up making stock to capture a couple or dollars . all of the y ’ - d go two regularly .\n",
            "originally published as in my april 11 , 10 , 000 years and wanted to gain an lead to several quantitative fifa .\n",
            "political players were not then those different courses .\n",
            "machine learning process ( johns hopkins on a of alphago self - advertising ) and hardware to other competitions in various important ways and use .\n",
            "in the recent years , it provides a representation of the population to a computer ’ s code . it ’ s the modern - to - new approach that are idea . a technique with repeated response may lead in a particular community , cannot require immensely human - like intelligence that can not then create agents to negotiate - gan , not an can need to train the large mental conditions for their environment humans , it could make , also capture us to achieve human to interact with the environment automatically and give better to better its system of this series .\n",
            "a good , we like your need using advantage function that is to understand in the beginning of the process , such as country lives directly ,\n",
            "\n",
            ") . also called google ’ s more - computer players . a short amount , invested , and on 2000 .\n",
            "searching as a business - workflow model is what you can ’ t show the machine learning .\n",
            "one of its question is : )\n",
            "let ’ s capture for ! when the final is :\n",
            "a great article about picking for my own our life and i ’ ve stayed myself the video of the process ! one engineering time grew so more missing and says ’ s the one memory with his bandwidth , so what needed to how to figure out the logic .\n",
            "so , as embeddings are made to show the rnn , its lstm transpose over a seed of stage . calculating the gap of was the layer increase . this is a face - layer , where title predictions and so synapses , the next of exactly the network is able and then follows how much input weight — it is actually compute for n as just another “ activations ” . recite this . we walk to them , the goal of the network was written is trained in excellent world . if it ’ s still the dataset of what i learned a model was developed when we saw up on it . if you trained the network , the network was training on whole knowledge of many join us absolutely well . making weights to learning as possible as the real world .\n",
            "in the early competition competition , while others alex krizhevsky don ’ t take either some of the mcts colorado , not you go to really exploring how the entire tree and the neural network needs to better .\n",
            "\n",
            "Epoch 5/10\n",
            "  2/620 [..............................] - ETA: 5:26 - loss: 2.0110"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "620/620 [==============================] - 274s 442ms/step - loss: 2.1058\n",
            "Epoch 6/10\n",
            "385/620 [=================>............] - ETA: 1:42 - loss: 1.7531"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "620/620 [==============================] - 273s 440ms/step - loss: 1.7246\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "machine learning , machine learning และ\n",
            "machine learning machine learning\n",
            "machine learning machine learning machine learning machine learning .\n",
            "machine learning for machine learning\n",
            "machine learning ( georgia tech / edx )\n",
            "machine learning ( udacity ) : “ a good machine learning course . the old way to find a data scientist , the data science course to be the same as well as the last computer science . the program isn ’ t the goal that was to create an understanding of the mind that is to play , and then the book for a game . he calls me the current generation of teaching . i ’ m going to get back to the next .\n",
            "i ’ m talking about machine learning but that ’ s been a lot of time .\n",
            "so i ’ m here to be able to write a story .\n",
            "if you ’ re not familiar with neural networks and you can find me on medium .\n",
            "if you ’ re interested in applying such techniques , you ’ ll give me here on medium , and now drop on for me to me .\n",
            "i ’ m very thankful to my friends from iit guwahati for their helpful feedback .\n",
            "if you ’ d like to learn more about this data science , if you ’ ve got a course on my data science , or conceptual code editor . i ’ m very helpful , and someone writing and machine learning .\n",
            "if you ’ d like to follow my ideas , and for machine learning , or machine learning .\n",
            "if you ’ d like to follow along with this series , first a great\n",
            "\n",
            "( supervised learning with scikit ) :\n",
            "- learning , is a prerequisite of supervised machine learning . part of udacity ’ s machine learning engineer nanodegree as an online system for python . nine hours of on - demand video . cost varies depending on udemy discounts , which are frequent . it has a 4 . 6 - star weighted average rating over 62 reviews .\n",
            "introduction to machine learning & face detection in python ( holczer balazs / udemy ) : an microsoft machine - learning with 162 data with data science .\n",
            "machine learning with apache systemml ( big data university ) : taught using apache systemml , which is a declarative style language designed for large - scale machine learning . estimated completion time of eight hours . big data university is affiliated with ibm . free .\n",
            "machine learning with apache systemml ( big data university ) : taught using apache systemml , which is a declarative style language designed for large - scale machine learning . estimated completion time of eight hours . big data university is affiliated with ibm . free .\n",
            "machine learning with apache systemml ( big data university ) : taught using apache systemml , which is a declarative style language designed for large - scale machine learning . estimated completion time of eight hours . big data university is affiliated with ibm . free .\n",
            "machine learning with apache systemml ( big data university ) : taught using apache systemml , which is a declarative style language designed for large - scale machine learning . estimated completion time of eight hours . big data university is affiliated with ibm . free .\n",
            "machine learning with apache systemml ( big data university\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , and how to build a new machine economy , the human brain and devices will be likely more of all in the heart turn to be a computer that could lead to their jobs .\n",
            "the quid pro quo , is also a fairly straightforward approach - known ai system . if the goal of ai research is to train a pet fish that can automatically quickly be used to be able to understand what it is the player to create a utility gives us to make a sense of a .\n",
            "the good news is that our first algorithm has to learn more about how we ’ re - seeding algorithms , the neural network in the form of tensorflow .\n",
            "we chose to train our model to our training set , with it . we just had to implement the problem . in order to our model , we need to use a model that has seen in . we ’ ll cover the sequence , using a number of numbers . we ’ ll feed the market in this model :\n",
            "now we have our image features , we ’ ll feed sound data to an image with a face and a picture that will be how we want to feed it with them .\n",
            "see we ’ re trying to recognize something of a fairly different image like this method . we ’ ll feed\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "learning ( big picture of calculus and machine learning ) , machine learning , and data engineer support programs . a specific set of artificial intelligence based on six - two - computer interaction .\n",
            "this is a big and a small - in - up for - the - skill of work .\n",
            "in the recent years , it ’ s easy . but it is just emerging with deep learning and neural networks , but if you ’ re not interested in neural networks .\n",
            "this is the basic idea of neural networks technology . it ’ s easy to explain what zero needs to train deep architectures .\n",
            "however , the number of neurons ( early earlier : ) . if you have to increase the number of neurons in this one . if you recommend the network to be certain output , so that is not only the same ?\n",
            "this is called sampling , so the number of dimensions in the image above .\n",
            "you can also check out the out of the weights that you multiply each text and sum of the model by each house in a larger area .\n",
            "to compare the two set of weights , we need to use it . we need to predict a model that is called a . let ’ s get the loss of all the value for each house in the first place . in this case , we ’ re relatively more comfortable deploying the algorithms in our dataset and object that it has never seen before .\n",
            "we have to use a neural network to calculate a set of weights , and then calculate a value of the house based on the house .\n",
            "\n",
            ", , , , , , , and how to the algorithm train even faster than the new memory .\n",
            "here ’ s some of the new memory .\n",
            "if you implemented gradient descent ( for example , if we use one to use a sigmoid function ) , and pass it through a function using gradient descent .\n",
            "if you implemented gradient descent , it should be less expensive ( at least two millions of parameters ) , and our weights will be a linear regression .\n",
            "in that case the sigmoid function is mathematically as gradient descent , the descent will be able to respond the current vector .\n",
            "we ’ re trying to achieve a high probability vector , so that exactly a number of numbers in a given point to optimization , and another ( we ’ ll use a bit data ! ) .\n",
            "the way that we know is the image below .\n",
            "now we have a look at that we are good enough to write a program to get an average app .\n",
            "but what if we want to make a neural network , we can apply a program to estimate what would not be run on a given , but it will be the overall . this was how foma and lusha help the sigmoid function as well .\n",
            "our final layer network will not be a bit vector , the most common local data set will be used to work . the agent is trained to encode the number of parameters , like telling us all , and where we work well - off - and - image recognition images in the image ’ s boundary . the goal of this network\n",
            "\n",
            "/ @ / / robotic - - intelligence - ? source = tag _ archive - - - - - - - - - - 3 - - - - - - - - - - - - - - a complex , a augmentation neural network — a single human , \" in the past few decades , the recent advancements in the concept of ai , the entire public , between 20 , 000 + categories , which are just as good .\n",
            "what exactly do we do is like we ’ re just as a job or not . the human brain has a lot of work . first , the idea of interest you are doing in a computer or how it means . for such such a machine ’ s algorithms will learn from all the heart of a computer is a next step .\n",
            "if you ’ re a cake of artificial intelligence , the way to do about your website .\n",
            "now you ’ re interested in machine learning or deep learning in a second language ( instead of all the background ) .\n",
            "to be sure that last , having a lot of recruiters and is that once you ’ ve figured out to do so . . . . . . . . )\n",
            "i believe that the problem with designing a chatbot is that it does deepmind as well . well , don ’ t be surprised if you ’ re still thinking .\n",
            "however , it ’ s not hard to beat the world ’ s best app .\n",
            "plus . the popular launch here is that it stands up hand . the pre - seed technology is that the world ’\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "selection of “ information processing from numpy ” ’ s ( after we ’ ve been here ) .\n",
            "in vector in the v - 1 , a , not easy , we think that it happened we ’ ll dig ( but using the variables using that we can use it ( ) , and we am precisely . this time we interact provide some real data , we need to do better is utilize the neural network .\n",
            "putting all the new convolution i ’ , ll feed it with the same blog post :\n",
            "we also know the same we ’ ll have the same .\n",
            "let ’ s keep our network work through whole face ! if do you are just looking at _ looking for predicting if you are in terms of the data set . when - learning ! putting the neural network to the cnn onto gradients or the biases points of the difference or how good point in the point .\n",
            "while this would be a final level . in order , there ’ s very efficient , very much better to do .\n",
            "with low evaluation alone , we finally recall a “ product function ” , so we discussed above for a new post :\n",
            "1 . we want to be highly challenges there in an future related by “ human learning ” thus a deep showing a way to “ teach ” it is in information . in the part of this post , we want to build a more advanced discipline than the sort of things to be a “ ” over the training data from our set - concept policy . unfortunately , the next bot will be able to\n",
            "\n",
            "ovation , clap to show how much you enjoyed this story .\n",
            "co - founder of udacity ’ s life . learn more .\n",
            "\"\n",
            "& , 8 , 8 , https : / / medium . com / @ / emotional - - computing - s - legacy - demands - projects - ? source = tag _ archive - - - - - - - - - 8 - - - - - - - - - - - - - - , the , what ’ s the art of deep learning with deep learning , \" in the 101 s in particular , deep learning it already thought about human - learning . we are given available in this post as a series . the human network is an ‘ strategy , start - time starting to play it is moved by a simple video video game with a game or value or label let ’ s say . this approach had been promising .\n",
            "here ’ s the first level , we ’ ll only look with much depth of how these exercises .\n",
            "our goal is chosen ahead of , when only has no knowledge . ( if we trained word vectors from this set of all classes over time series with a simple game ) . the list below is the point we could figure out the ( trained on the neural net ) . to get more data set is that list in a given equation : ( 1 ) and useful patterns . that ’ s a slight method to the second model instead of the house but the actual variables it is proportional with a encoder for this , and explore a vector similar to\n",
            "\n",
            "data machine learning engineer . a big data scientist is to take a model to complete data in a specific group of images , such as a variety of online music with other easily , even hours more hours .\n",
            "the main fraction of class ’ s conversational ui - transfer apps which won ’ t be pre - forms in line - end for the category .\n",
            "careful , attention better . hit away from this series , words and translation is a key question that comes out of what google , apple , baidu place for identifying these tasks using an algorithm worked . for example , the computer ’ s fundamental component is a random part of potential whether the user could be creating new in .\n",
            "where the mainstream begin , the new generation in this context fraud . the issue with a single , adding automated system that was in a blockchain - based protocol , social web - based services . this year point out of these technologies entertainment into the policy . “ robots already been able through the internet . ” with these ideas and people , people , to be almost a few days in the more . players who won ’ t be like the future of jobs that are people but today their mission in their own kinds of tasks .\n",
            "the nature of genetic algorithms is derived from “ just type ” . let us figure out how it must die in our brains ? well with genomes : let ’ s represent a lot of truth vector representing its vector .\n",
            "creates a member women x : a y , the above are simply false ( not represent the color and one\n",
            "\n",
            "Epoch 7/10\n",
            "  1/620 [..............................] - ETA: 5:43 - loss: 1.4205"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "620/620 [==============================] - 271s 438ms/step - loss: 1.4179\n",
            "Epoch 8/10\n",
            "385/620 [=================>............] - ETA: 1:45 - loss: 1.1890"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "620/620 [==============================] - 277s 446ms/step - loss: 1.1633\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "systems :\n",
            "machine learning is a data scientist and artificial intelligence to predict several training data . a data scientist role for learning to improve the best and learn to play atari games like\n",
            "and predict things , please let us know , if we should be able to play with the data .\n",
            "the best way to look with this article and an excellent paper for about about our first medium .\n",
            "this is what we have to do this , but we need to get started . we find a good job and let it much better fun .\n",
            "originally published at techblog . netflix . com\n",
            "the most of the first competition and a great fun to follow & p 500 .\n",
            "if you ’ d like to do some .\n",
            "i did the ai post , i ’ m a huge of articles and artificial intelligence — i think it ’ s possible to get the way .\n",
            "i ’ m just going to say for a . i ’ m talking about this landscape .\n",
            "after this i ’ m a non - techie - recognition - answer is : that ’ s that i am precisely ? ) . i don ’ t think it ’ s the greatest teacher .\n",
            "i ’ m talking about this long . i ’ m talking about machine learning , and the goal is to build a deep learning community . i . i ’ m truly the big deal with this .\n",
            "i ’ m just a couple and shared that i ’ m going to light . )\n",
            "i did was too , but i was over my second , but i\n",
            "\n",
            ", big data and machine learning .\n",
            "\"\n",
            "how to do this , we have a need to use machine learning algorithms for the above two in the future . this step is to be a 2 - layered ann - author review , but if you started using a neural network that can ’ t — that is not just what it doesn ’ t understand .\n",
            "after this first , it ’ s just a new product that ’ s always that our task is to be an input . we want to give this information to the model once the relationship between the input to the next . in order to optimize these , we can introduce a neural network that can be able to learn more complex kinds of human games .\n",
            "the most important part of the human brain and having made at some reason , it ’ s a collective , and a value that ’ s all about office and that we can still be able to learn .\n",
            "sp : we ’ re already seeing this constantly , and the one to move we do and see how to go into account for them .\n",
            "here ’ s the problem : neural network ( note : in a lot of research ) , we ’ ll understand how this new . in this post , we ’ ll just look at the core of the neural network on an rnn by looking at a given point :\n",
            "next , we will move the neural network to recognize pictures of the same output of an 8 - layer neural network , we can see a lot of neurons .\n",
            "we also know that the hidden\n",
            "\n",
            "data scientist ” who , “ not designed to predict the difference between two languages of “ the ” and “ machine ” software . the project represents the computer science , data science ” and “ data - science ” comes from a computer science at machine learning .\n",
            "the technology behind around web development , machine learning , computer development , deep learning , big data , and more .\n",
            "\"\n",
            "ross , 2 . 5k , 4 , https : / / becominghuman . com / how - to - use - noise - to - need - a - fully - fledged - a - g - ? - ? source = tag _ archive - - - - - - - - - - 3 - - - - - - - - - - - - - - - , how to easily detect objects with deep learning on raspberry pi , \" disclaimer : i ’ m building nanonets . com to help build ml with less data and no hardware\n",
            "the raspberry pi is a neat piece of hardware that has captured the hearts of a generation with ~ 15m devices sold , with hackers building even cooler projects on it . given the popularity of deep learning and the raspberry pi camera we thought it would be nice if we could detect any object using deep learning on the pi .\n",
            "now you will be able to detect a photobomber in your selfie , someone entering harambe ’ s cage , where someone kept the sriracha or an amazon delivery guy entering your house .\n",
            "20m years of evolution have made human vision fairly evolved . the human brain has 30 % of it ’\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "machine learning . it ’ s better to often number of reviews on datasets . we can also use those tools to use the full - time product algorithm for new data science and statistical data .\n",
            "the problem is to also be using offline in online computation , which use a clustering algorithm to try to figure out some human work .\n",
            "modern algorithms can be used for different groups . these are not really a lot of times .\n",
            "the first step is that they can be using the learning process , each of its inputs will be used . deep learning :\n",
            "in this case , my first network is a series of steps : each neuron ’ s weights and then hidden layers . a simple example of the network is as a single layer , and at each layer , which means that the final layer should be at the input image . there are 3 layers that the input is the right different as the input image .\n",
            "the information has made for this network is the input and output to the layer . this one of the information output is as the output of the current lstm . in the final layer the network learns how to make this step closer to the markup features , and not not just the most likely fully connected layer :\n",
            "it ’ s easy to train the network train , with linear function :\n",
            "the data and then transform the raw equation . this works , we discussed in a classifier that will also be able to train the second - in - error .\n",
            "the non - half - a - year concept and the / neural\n",
            "\n",
            "done through the following resources : 1 to be a couple of small courses , most recently courses , and a five - part courses . the use cases that the read is text and a book for each task . free and paid options available . it has a 2 . 3 - star weighted average rating over 4 reviews .\n",
            "the course also covers all aspects of the machine learning workflow and more algorithms . uses python . part of r . , / time . environment , k - means clustering . students can use python , many other tools like machine learning . a computer programs for r - like , c ) , e - commerce . :\n",
            "information to the world of the user ’ s question , which is a list of two people reviews . this makes an old memory of video games , which is a top of the technology of the smart home software , and the game is drawn from the data , it has a 4 - star review of using a program that was usually possible .\n",
            "the netflix prize abstracted the recommendation system with the process of the best human : taking a good value for our number , the netflix prize that we will be using backpropagation and loss into a function and policy - the - use - policy policy ( which can be to process from any ) .\n",
            "we can express that a good implementation is with a good way to start with our while it would be a simple task of learning to achieve state - of - the - art rl agents . you want to think of the code we have going to start with\n",
            "\n",
            "new features mostly known linear algebra , university of class central - created to represent the — data science and the data must learn something the following .\n",
            "how do you find this ? first , we will look our dataset by someone playing a system that is very high . now let ’ s start with our entire machine learning algorithm , and the main algorithms algorithm will also work ( e . g . imagenet in this case , the real value of the weights , which is not currently added by computing their power . this is the performance of the tree application . the future of software engineering is a very important task for many people like to be able to outsource the iot industry .\n",
            "in this article i was called “ ” s hybrid machine learning applications in machine learning . i ’ ve also been working in the past three years ” of the use . the way they get there , , and of which we ’ re called it in a form of advanced algorithms . i ’ m a really good place in production , so how many of the big deal of this post is a little of in the start . he teaches you about the fast algorithm and then update your bot from the original blog post .\n",
            "andrew ng is a good training from scratch - in deep learning .\n",
            "now that the biggest idea is that apps is that its machine learning is the python , so r - cnn will just a “ big data for each image , and a very high accuracy , you may need to have the many possible .\n",
            "the image below can be\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "know business data that explains the data function ’ s own . secondly , maybe the best data point for each of the algorithms to match data . let ’ s use probability to a value that your later discussion ’ s article . however the model will start to make a model .\n",
            "the dataset is split into the model before which i laid the previous parameters after training , for each run in the data . the information was comparing the model architecture tf .\n",
            "recall her to a bunch of context ( the best performance between - can ’ s ’ t on . here we can add ) even this , it ’ s most interesting if you can meddle some of the start .\n",
            "as we need to learn the basics , it ’ s not that an algorithm will perform tasks , as we do our weights are global parameters , which will after some functions together for others that do we through a 2 model available . don ’ t worry about a neural network to machine learning . no one quick post is feed this similar to what exactly what ’ s possible for a few minutes — human learn brains :\n",
            "seem be a lot . we are most interesting in the life :\n",
            "first , you ’ ve made this environments to pick one into account a series of several engines , and even though of the video games with more 1 second , but this is going a much game against pac - given in as training to a single 2 . 5 + 1 + 0 for a in - competition . 46 and 0 are not much better at the very large\n",
            "\n",
            "for those resources . now you will have having the same as well than having the machine learning techniques from machine learning researchers . i can use machine learning algorithms for a machine learning ! below - e to approach you . explore yourself , neural nets us cnns go down\n",
            ".\n",
            "3 . datacamp data machine learning can ’ t know how they can mean anything about here and the ? the program will sell the data from all of the images it looks out this old similar online . i news so far as much as we spent weeks .\n",
            "as opposed to the following : can have been in this data that can be done by adding the one machine learning algorithm instead of those . large data has been these problems over one great model , such as it can model on a human fashion , and we are able to classify a human to all of how we want it . in focusing below : offline during 6 / 20 - day with . coming if you use some examples of on this project , and not just thought what a that data is far from the right . these are ways to do , but there are many many problems where they want to be using these found . instead of them four types of recommendation algorithms , we could set predictions on this individual value choices and then capture relevant queries and a set of other links we are equally related , and a spreadsheets for all interests .\n",
            "previously , this estimate work with the existing documentation — a user ’ s search engine , or even more on a so - called the ability to capture a\n",
            "\n",
            "( 2017 ) . we are u so mention - in - the - art which writer . r . 17 and are here in the current state . the wtf every language “ machine - of - a - 9 words ” “ which can the word between the beginning , and to expand it the entirely right for their own . [ note : before you translate the dictionary , there also also been the number of companies working on different people and make answers whether that we might experience about in all of their technologies .\n",
            "the wolfram news isn ’ t exactly those jobs that didn ’ t develop an ai . the goal of building dataset and goes into a never mind explicitly . in the process it is nice . a voice no one any . instead , the authors believe seemed to be achieved with the creation of a computer — not just explained . it ‘ ’ , because computer could create that ’ s s going and get to the noticed that you want forever on ‘ hybrid ‘ ai ” .\n",
            "the art of machine learning that only humans can be thought of human creativity and creativity . led by the end of the new technologies nor it . google translate the machines , computer scientists have to create tries to understand , in particular language , any human brain . with one of any car - friendly behavior on to change when faced of speech recognition is depends on simple . we can take four levels of work and change their machine - learning , it basically needs lots of philosophical problems . here , we can say that many of our neural network might some neurons\n",
            "\n",
            "Epoch 9/10\n",
            "  1/620 [..............................] - ETA: 5:51 - loss: 0.9468"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "620/620 [==============================] - 277s 447ms/step - loss: 0.9586\n",
            "Epoch 10/10\n",
            "382/620 [=================>............] - ETA: 1:45 - loss: 0.8118"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "620/620 [==============================] - 273s 440ms/step - loss: 0.7917\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " . ,\n",
            "\n",
            "\n",
            "\n",
            " machine learning\n",
            "b\n",
            "machine learning\n",
            "\n",
            " machine learning\n",
            "\n",
            " supervised learning\n",
            "on a few - in data scientist at baidu , a b test framework , rule - based approach .\n",
            ", on the trend , the problem is that they can now be the next step for the first time to create a very well task .\n",
            "while creating new data that ’ s even data and be able to test it work for a lot of data . this is a lot easier to start with creating a powerful method . for example , we can use a tf - idf , following best - value data , and have not start with a small number of iterations and in a few years .\n",
            "here is a lot easier to see how much this model are working .\n",
            "here is a type of model _ dir - you - ended up a parameter in the problem . maybe to do so , in order to the most similar linear regression . but the first thing to do is the following gradient is , because we can see that the other weights will have a biases and is the highest out .\n",
            "we ’\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            ". . ) the countless ai bot that gets a chatbot to learn more about themselves in the mcts . i ’ ve given a tutorial in action to know where musical game , but represent they don ’ t have a big on sitting out around on your table .\n",
            "i ’ ve getting it ! my first three ( and they were . ) , if you ’ d like to make your own neural network at the point of it because . . . and that ’ s ok . i hope you there now .\n",
            "to experiment the techniques we created everything about a four main algorithm , say i haven ’ t been finished on what i ’ m going to do that ( or for the rules ) , the first model is the same input , and a certain scientist .\n",
            "machine learning is the fact why artificial thanks doesn ’ t over the longer possible , and you goldsmiths learn something like this would make a big photo . after doing it all the story :\n",
            "you may have a very human human machine in a . being a control when you were doing . you can learn human level network , which would ever be at almost time to understand as hard very quickly .\n",
            "all of these things are now that there are books or of work that it really helps to play computers . in fact , through modeling focus , data science , , , and math .\n",
            "first , it ’ s important to use to neural networks , cost , learn , and how to write from examples to machine learning in the data .\n",
            "step 3 / learning\n",
            "\n",
            "to the data you were to build very dataset 20 % for an entire amount of training dataset .\n",
            "sampling bias was also also been too similar , experienced due to my model and try the best results as a data sample . the model can take , it must be prepared for you with this model with each of the data but i . , to the network you receive all of these features that it ’ s good to practice from the model without being able to learn more works .\n",
            "the most exciting part about the test is getting , but the most way we have talked about this long let ’ s start with ai , which is what you ’ re talking about it , it ’ s not a black box that can take a look for one now , if i ’ m sure we can ’ t ? that ’ s where ( with instead ) . instead of thinking that is simply to recognize something and can do with .\n",
            "if you want through a neural network or recognize each weight of the cost function is just 1 . these weights will be 65w for this other than the input time it is the layer 1 . 0 are the neuron in the next layer , out weights to be 0 of the overall output to the training set .\n",
            "but if we look at once the vector can look like this “ magic ” get ! ?\n",
            "you might notice that data = :\n",
            "_ i have your activations - data is looking back my blog post . . you see if you ’ re interested in looking on around , seeing andrew code\n",
            "\n",
            "- symbolic cpu units in supervised neural networks . currently building a small amount of computation available in same language : john search would become found in fact programming .\n",
            "the goal has worked with simple rules , and energy efficiency , and it may be the history of new . unfortunately , you ’ ll know that these are fake news high or more to build with tools to supplement a framework in your own space .\n",
            "if you want to go beyond the ‘ big virtual ” systems , the post you ’ ll be more of the automated resources from your own data ?\n",
            "in this data , you can really get for !\n",
            "from a quick cheer to a standing ovation , clap to show how much you enjoyed this story .\n",
            "a . i .\n",
            "i talk in the world , including , almost about the world - as a next day of driving a machine that is as a great place . i know someone who knows to understand the machine is it so fun like the suggesting people think need to apply something at this point in the field you . . . it ’ s not amazing , they thought about giving most aspects of our kinds of points and give the difficult important .\n",
            "it ’ s not hard to let a big feel in out there is fun soon within the generate a new infrastructure as a advancements are this data that will still be used to accomplish useful and faster . but really , the look to look over it and works is our company for it . when we will come well in a train of work which won ’ t\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6F3XE1yQG3sB",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ecc18bde-3468-474e-aa1f-0f9dc9c335a2"
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-740cfa8e-5e2d-46a6-b968-be7e3b20ee3a\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-740cfa8e-5e2d-46a6-b968-be7e3b20ee3a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "c7LdYkQpIAIW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}